{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Due: 4 PM on Wednesday, 10 Feb 2016**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions\n",
    "-----\n",
    "\n",
    "Write code to solve all problems. The grading rubric includes the following criteria:\n",
    "\n",
    "- Correctness\n",
    "- Readability\n",
    "- Efficiency\n",
    "\n",
    "Please do not copy answers found on the web or elsewhere as it will not benefit your learning. Searching the web for general references etc is OK. Some discussion with friends is fine too - but again, do not just copy their answer. \n",
    "\n",
    "**Honor Code: By submitting this assignment, you certify that this is your original work.**\n",
    "\n",
    "**Note**: These exercises will involve quite a bit more code writing than the first 2 homework assignments so start early. They are also intentionally less specific so that you have to come up with your own plan to complete the exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following data sets:\n",
    "```python\n",
    "titanic = sns.load_dataset(\"titanic\")\n",
    "iris = sns.load_dataset(\"iris\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1 (20 pts)** Working with `numpy.random`.\n",
    "\n",
    "**Part 1 (10 pts)** Consider a sequence of $n$ Bernoulli trials with success probabilty $p$ per trial. A string of consecutive successes is known as a success *run*. Write a function that returns the counts for runs of length $k$ for each $k$ observed in a dictionary.\n",
    "\n",
    "For example: if the trials were [0, 1, 0, 1, 1, 0, 0, 0, 0, 1], the function should return \n",
    "```\n",
    "{1: 2, 2: 1})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2 (10 pts)** Continuing from Part 1, what is the probability of observing at least one run of length 5 or more when $n=100$ and $p=0.5$?. Estimate this from 100,000 simulated experiments. Is this more, less or equally likely than finding runs of length 7 or more when $p=0.7$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2. (30 pts)** \n",
    "\n",
    "Using `RandomForestClassifier` from `sklearn`, find the 5 most important predictors of survival on the Titanic. Compare the accuracy of prediction using only these 5 predictors and using all non-redundant predictors. Some intial pre-processing code is provided. Hint: check out the `pandas.get_dummies()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic = sns.load_dataset(\"titanic\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic.drop(['alive', 'embarked', 'class', 'who', 'adult_male'], axis=1, inplace=True)\n",
    "titanic.dropna(axis=0, inplace=True)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2. (25 pts)**\n",
    "\n",
    "Using `sklearn`, perform unsupervised learning of the iris data using 2 different clustering methods. Do NOT assume you know the number of clusters - rather the code should either determine it from the data or compare models with different numbers of components using some appropriate test statistic. Make a pairwise scatter  plot of the four predictor variables indicating cluster by color for each unsupervised learning method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3. (50 pts)**\n",
    "\n",
    "Write code to generate a plot similar to the following ![figure](http://mathworld.wolfram.com/images/eps-gif/ElementaryCA_850.gif) using the explanation for generation of 1D Cellular Automata found [here](http://mathworld.wolfram.com/ElementaryCellularAutomaton.html). You should only need to use standard Python, `numpy` and `matplotllib`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it simpler, I have provided the code for plotting below. All you need to do is to supply the `make_ca` function (which may of course use as many ohter custom functons as you deem necessary). As you can see from the code below, the `make_ca` function takes 3 arguments\n",
    "```\n",
    "rule - an integer e.g. 30\n",
    "init - an initial state i.e. the first row of the image\n",
    "niter - the number of iterations i.e. the number of rows in the image\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.ticker import NullFormatter, IndexLocator\n",
    "\n",
    "def plot_grid(rule, grid, ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.subplot(111)\n",
    "    with plt.style.context('seaborn-white'):\n",
    "        ax.grid(True, which='major', color='grey', linewidth=0.5)\n",
    "        ax.imshow(grid, interpolation='none', cmap='Greys', aspect=1, alpha=0.8)\n",
    "        ax.xaxis.set_major_locator(IndexLocator(1, 0))\n",
    "        ax.yaxis.set_major_locator(IndexLocator(1, 0))\n",
    "        ax.xaxis.set_major_formatter( NullFormatter() )\n",
    "        ax.yaxis.set_major_formatter( NullFormatter() )\n",
    "        ax.set_title('Rule %d' % rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "niter = 15\n",
    "width = niter*2+1\n",
    "init = np.zeros(width, 'int')\n",
    "init[width//2] = 1\n",
    "rules = np.array([30, 54, 60, 62, 90, 94, 102, 110, 122, 126, \n",
    "                  150, 158, 182, 188, 190, 220, 222, 250]).reshape((-1, 3))\n",
    "\n",
    "nrows, ncols = rules.shape\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*3, nrows*2))\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        grid = make_ca(rules[i, j], init, niter)\n",
    "        plot_grid(rules[i, j], grid, ax=axes[i,j])\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
